---
## general
spamassassin_user: debian-spamd
spamassassin_group: debian-spamd
spamassassin_home_dir: /var/lib/spamassassin
spamassassin_log_dir: /var/log/spamassassin
spamassassin_syslog_facility: "{{ spamassassin_log_dir }}/spamd.log"

# Write spamassassin config files (only install spamassassin and configure
# cronjob if set to False)
spamassassin_configure: True

## file: /etc/default/spamassassin

spamassassin_automatic_rule_update_enabled: true
spamassassin_nice_level: 0
spamassassin_pidfile: /var/run/spamd.pid

## file: /etc/spamassassin/local.cf

# Rewrite the mail header?
spamassassin_rewrite_header_enabled: false
spamassassin_rewrite_header: "Subject *****SPAM*****"

# Allowed 0, 1, 2 see
# https://spamassassin.apache.org/full/3.0.x/dist/doc/Mail_SpamAssassin_Conf.html
spamassassin_report_safe: 0

# Set the score required before a mail is considered spam
spamassassin_required_score: 5.0

# Whether to use the naive-Bayesian-style classifier built into SpamAssassin.
spamassassin_use_bayes: 1

# Whether to use rules using the naive-Bayesian-style classifier
# built into SpamAssassin.
spamassassin_bayes_auto_learn: 1

# Where to store bayes db
spamassassin_bayes_path: "{{ spamassassin_home_dir }}/bayes_db"

# The file mode bits used for the Bayesian filtering database files.
#
# Make sure you specify this using the 'x' mode bits set, as it may also be
# used to create directories. However, if a file is created, the resulting file
# will not have any execute bits set (the umask is set to 111).
spamassassin_bayes_file_mode: "0700"

# What networks or hosts are 'trusted' in your setup.
spamassassin_trusted_networks: []

# Tells SpamAssassin whether DNS resolving is available or not. A value yes
# indicates DNS resolving is available, a value no indicates DNS resolving is
# not available - both of these values apply unconditionally and skip initial
# DNS tests, which can be slow or unreliable.
# When the option value is a test (with or without arguments), SpamAssassin
# will query some domain names on the internet during initialization,
# attempting to determine if DNS resolving is working or not. A space-separated
# list of domain names may be specified explicitly, or left to a built-in
# default of a dozen or so domain names. From an explicit or a default list a
# subset of three domain names is picked randomly for checking. The test
# queries for NS records of these domain: if at least one query returns a
# success then SpamAssassin considers DNS resolving as available, otherwise
# not.
# The problem is that the test can introduce some startup delay if a network
# connection is down, and in some cases it can wrongly guess that DNS is
# unavailable because a test connection failed, what causes disabling several
# DNS-dependent tests.
# Please note, the DNS test queries for NS records, so specify domain names,
# not host names.
# Since version 3.4.0 of SpamAssassin a default setting for option
# dns_available is yes. A default in older versions was test.
# Quotes are important, don't miss them!
spamassassin_dns_available: "yes"

# Specifies an IP address of a DNS server, and optionally its port number. The
# dns_server directive may be specified multiple times, each entry adding to a
# list of available resolving name servers. The ip-addr-port argument can
# either be an IPv4 or IPv6 address, optionally enclosed in brackets, and
# optionally followed by a colon and a port number. In absence of a port number
# a standard port number 53 is assumed. When an IPv6 address is specified along
# with a port number, the address must be enclosed in brackets to avoid parsing
# ambiguity regarding a colon separator. A scoped link-local IP address is
# allowed (assuming underlying modules allow it).
# spamassassin_dns_servers:
#   - 127.0.0.1
#   - 127.0.0.1:53
#   - [127.0.0.1]:53
#   - [::1]:53
#   - fe80::1%lo0
#   - [fe80::1%lo0]:53
# In absence of dns_server directives, the list of name servers is provided by
# Net::DNS module, which typically obtains the list from /etc/resolv.conf, but
# this may be platform dependent. Please consult the Net::DNS::Resolver
# documentation for details.
spamassassin_dns_servers: []
  
# Allowed: nfsafe, flock, win32
spamassassin_lock_method: flock

# The score threshold below which a mail has to score, to be fed into
# SpamAssassin's learning systems automatically as a non-spam message.
spamassassin_bayes_auto_learn_threshold_nonspam: 0.1

# The score threshold above which a mail has to score, to be fed into
# SpamAssassin's learning systems automatically as a spam message.
#
# Note: SpamAssassin requires at least 3 points from the header, and 3 points
# from the body to auto-learn as spam. Therefore, the minimum working value for
# this option is 6.
spamassassin_bayes_auto_learn_threshold_spam: 12.0

# With bayes_auto_learn_on_error off, autolearning will be performed even if
# bayes classifier already agrees with the new classification (i.e. yielded
# BAYES_00 for what we are now trying to teach it as ham, or yielded BAYES_99
# for spam). This is a traditional setting, the default was chosen to retain
# backward compatibility.
#
# With bayes_auto_learn_on_error turned on, autolearning will be performed only
# when a bayes classifier had a different opinion from what the autolearner is
# now trying to teach it (i.e. it made an error in judgement). This strategy
# may or may not produce better future classifications, but usually works very
# well, while also preventing unnecessary overlearning and slows down database
# growth.
spamassassin_bayes_auto_learn_on_error: 0

# Controls which sources in a mail message can contribute tokens (e.g. words,
# phrases, etc.) to a Bayes classifier. The argument is a space-separated list
# of keywords: header, visible, invisible, uri, mimepart), each of which may be
# prefixed by a no to indicate its exclusion. Additionally two reserved
# keywords are allowed: all and none (or: noall). The list of keywords is
# processed sequentially: a keyword all adds all available keywords to a set
# being built, a none or noall clears the set, other non-negated keywords are
# added to the set, and negated keywords are removed from the set. Keywords are
# case-insensitive.
#
# The default set is: header visible invisible uri, which is equivalent for
# example to: All NoMIMEpart. The reason why mimepart is not currently in a
# default set is that it is a newer source (introduced with SpamAssassin
# version 3.4.1) and not much experience has yet been gathered regarding its
# usefulness.
#
# See also option bayes_ignore_header for a fine-grained control on individual
# header fields under the umbrella of a more general keyword header here.
#
# Keywords imply the following data sources:
#
# header - tokens collected from a message header section
# visible - words from visible text (plain or HTML) in a message body
# invisible - hidden/invisible text in HTML parts of a message body
# uri - URIs collected from a message body
# mimepart - digests (hashes) of all MIME parts (textual or non-textual) of
#            a message, computed after Base64 and quoted-printable decoding,
#            suffixed by their Content-Type
# all - adds all the above keywords to the set being assembled
# none or noall - removes all keywords from the set
#
# The bayes_token_sources directive may appear multiple times, its keywords are
# interpreted sequentially, adding or removing items from the final set as they
# appear in their order in bayes_token_sources directive(s).
spamassassin_bayes_token_sources:
  - header
  - visible
  - invisible
  - uri

# If you receive mail filtered by upstream mail systems, like a spam-filtering
# ISP or mailing list, and that service adds new headers (as most of them do),
# these headers may provide inappropriate cues to the Bayesian classifier,
# allowing it to take a "short cut". To avoid this, list the headers using this
# setting. Header matching is case-insensitive. Example:
spamassassin_bayes_ignore_header:
  - X-Bogosity
  - X-Spam-Flag
  - X-Spam-Status

# Bayesian classification and autolearning will not be performed on mail from
# the listed addresses. Program sa-learn will also ignore the listed addresses
# if it is invoked using the --use-ignores option. One or more addresses can be
# listed, see welcomelist_from.
#
# Spam messages from certain senders may contain many words that frequently
# occur in ham. For example, one might read messages from a preferred
# bookstore but also get unwanted spam messages from other bookstores. If
# the unwanted messages are learned as spam then any messages discussing
# books, including the preferred bookstore and antiquarian messages would be
# in danger of being marked as spam. The addresses of the annoying
# bookstores would be listed. (Assuming they were halfway legitimate and
# didn't send you mail through myriad affiliates.)
#
# Those who have pieces of spam in legitimate messages or otherwise receive ham
# messages containing potentially spammy words might fear that some spam
# messages might be in danger of being marked as ham. The addresses of the spam
# mailing lists, correspondents, etc. would be listed.
spamassassin_bayes_ignore_from: []

# Bayesian classification and autolearning will not be performed on mail to the
# listed addresses. See bayes_ignore_from for details.
spamassassin_bayes_ignore_to: []

# The Bayes system will, by default, learn any reported messages
# (spamassassin -r) as spam. If you do not want this to happen, set this option
# to 0.
spamassassin_bayes_learn_during_report: 1

# What should be the maximum size of the Bayes tokens database? When expiry
# occurs, the Bayes system will keep either 75% of the maximum value, or
# 100,000 tokens, whichever has a larger value. 150,000 tokens is roughly
# equivalent to a 8Mb database file.
spamassassin_bayes_expiry_max_db_size: 150000

# If enabled, the Bayes system will try to automatically expire old tokens from
# the database. Auto-expiry occurs when the number of tokens in the database
# surpasses the bayes_expiry_max_db_size value. If a bayes datastore backend
# does not implement individual key/value expirations, the setting is silently
# ignored.
spamassassin_bayes_auto_expire: 1

# Time-to-live / expiration time in seconds for tokens kept in a Bayes
# database. A numeric value is optionally suffixed by a time unit
# (s, m, h, d, w, indicating seconds (default), minutes, hours, days, weeks).
#
# If bayes_auto_expire is true and a Bayes datastore backend supports it
# (currently only Redis), this setting controls deletion of expired tokens from
# a bayes database. The value is observed on a best-effort basis, exact timing
# promises are not necessarily kept. If a bayes datastore backend does not
# implement individual key/value expirations, the setting is silently ignored.
spamassassin_bayes_token_ttl: "3w"

# Time-to-live / expiration time in seconds for 'seen' entries (i.e. mail
# message digests with their status) kept in a Bayes database. A numeric value
# is optionally suffixed by a time unit (s, m, h, d, w, indicating seconds
# (default), minutes, hours, days, weeks).
#
# If bayes_auto_expire is true and a Bayes datastore backend supports it
# (currently only Redis), this setting controls deletion of expired 'seen'
# entries from a bayes database. The value is observed on a best-effort basis,
# exact timing promises are not necessarily kept. If a bayes datastore backend
# does not implement individual key/value expirations, the setting is silently
# ignored.
spamassassin_bayes_seen_ttl: "8d"

# If this option is set, whenever SpamAssassin does Bayes learning, it will put
# the information into the journal instead of directly into the database. This
# lowers contention for locking the database to execute an update, but will
# also cause more access to the journal and cause a delay before the updates
# are actually committed to the Bayes database.
spamassassin_bayes_learn_to_journal: 0

# manual welcomelisting
spamassassin_welcomelist: []

# Add addtional update channels, which should be updates by the daily
# sa-update cronjob. E.g.:
# spamassassin_additional_update_channels:
#   - address: spamassassin.heinlein-support.de
#     gpg: no
spamassassin_additional_update_channels: []

# Option allows disabling of rules which would result in a DNS query to one of
# the listed domains. The first argument must be a literal allow or deny,
# remaining arguments are domains names.
#
# Most DNS queries (with some exceptions) are subject to dns_query_restriction.
# A domain to be queried is successively stripped-off of its leading labels
# (thus yielding a series of its parent domains), and on each iteration a check
# is made against an associative array generated by dns_query_restriction
# options. Search stops at the first match (i.e. the tightest match), and the
# matching entry with its allow or deny value then controls whether a DNS query
# is allowed to be launched.
#
# If no match is found an implicit default is to allow a query. The purpose of
# an explicit allow entry is to be able to override a previously configured
# deny on the same domain or to override an entry (possibly yet to be
# configured in subsequent config directives) on one of its parent domains.
# Thus an 'allow zen.spamhaus.org' with a 'deny spamhaus.org' would permit DNS
# queries on a specific DNS BL zone but deny queries to other zones under the
# same parent domain.
#
# Domains are matched case-insensitively, no wildcards are recognized, there
# should be no leading or trailing dot.
#
# Specifying a block on querying a domain name has a similar effect as setting
# a score of corresponding DNSBL and URIBL rules to zero, and can be a handy
# alternative to hunting for such rules when a site policy does not allow
# certain DNS block lists to be queried.
#
# Special wildcard "dns_query_restriction deny *" is supported to block all
# queries except allowed ones.
#
# Example:
#   spamassassin_dns_query_restrictions:
#     - deny dnswl.org surbl.org
#     - allow zen.spamhaus.org
#     - deny spamhaus.org mailspike.net spamcop.net
spamassassin_dns_query_restrictions: []
  
# Enable additional pyzor check
spamassassin_pyzor_enabled: True

spamassassin_pyzor_config_dir: /etc/spamassassin/.pyzor

# Enable additional razor chek
spamassassin_razor_enabled: True

spamassassin_razor_config_dir: /etc/spamassassin/.razor

# Enable spam training by users and domain
# spamassassin_spamtraining_users:
#    - domain: myfirstdomain.org
#      users:
#       - admin
#       - foo
#    - domain: myseconddomain.org
#      users:
#       - admina
#       - foobar
spamassassin_spamtraining_users: []

# Set custom spamassasssin rules
# spamassassin_custom_rules:
#   - |
#     header   SPF_FAIL	eval:check_for_spf_fail()
#     describe SPF_FAIL	SPF: sender does not match SPF record (fail
#     tflags   SPF_FAIL	net
#     reuse    SPF_FAIL
spamassassin_custom_rules: []

# Set custom spamassassin scores
# spamassassin_custom_scores:
#    - name: SPF_FAIL
#      score: "0 1.5 0 0.919"
spamassassin_custom_scores: []

spamassassin_packages:
  - libarchive-zip-perl
  - libbsd-resource-perl
  - libcompress-zlib-perl
  - libdbi-perl
  - libencode-detect-perl
  - libgeoip2-perl
  - libio-socket-ssl-perl
  - libmail-dkim-perl
  - libmail-dmarc-perl
  - libmail-spf-perl
  - libmaxmind-db-reader-perl
  - libnet-libidn2-perl
  - libnet-libidn-perl
  - libnet-patricia-perl
  - libpackage-stash-perl
  - libpackage-stash-xs-perl
  - spamassassin
  - spamc
  - spamd
